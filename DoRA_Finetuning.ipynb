{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sarvagya4/Banking77/blob/main/DoRA_Finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Day 4 â€“ DoRA (Weight Decomposed LoRA) Implementation**\n",
        "\n",
        "- Implement or integrate DoRA (Weight Decomposed LoRA).\n",
        "- Train the model with DoRA applied and compare results to LoRA and classic approaches.\n",
        "- Log DoRA configuration, training metrics, and comparison results to wandb.\n"
      ],
      "metadata": {
        "id": "6mL0Lcvyn9Vp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HS8OWZJOdjqj"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets wandb accelerate -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import warnings\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    DataCollatorWithPadding,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        ")\n",
        "from datasets import Dataset\n",
        "import wandb\n"
      ],
      "metadata": {
        "id": "p7pDo4-0dovi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "id": "D0SWYJmxdykR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IAv6h-jbdzxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "PEKeUIPjd1aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_path = '/content/drive/MyDrive/Banking77_Project/data/train.csv'\n",
        "val_path = '/content/drive/MyDrive/Banking77_Project/data/test.csv'\n",
        "\n",
        "print(f\"Attempting to load training data from: {train_path}\")\n",
        "print(f\"Attempting to load validation data from: {val_path}\")\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "val_df = pd.read_csv(val_path)\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0-JDpDmCd5Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "try:\n",
        "    train_dataset = train_dataset.rename_column(\"intent\", \"label\")\n",
        "    val_dataset = val_dataset.rename_column(\"intent\", \"label\")\n",
        "    print(\" Renamed 'intent' column to 'label'.\")\n",
        "except ValueError:\n",
        "    print(\"Column 'intent' not found or already named 'label'. Skipping rename.\")\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['text_cleaned'], truncation=True, max_length=128, padding='max_length')\n",
        "\n",
        "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
        "val_dataset = val_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "print(\" Data preprocessing and formatting complete.\")"
      ],
      "metadata": {
        "id": "6wHH7apPd8Bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "iD2V4q7ad-jR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DoRALayer(torch.nn.Module):\n",
        "    def __init__(self, linear_layer, rank=8, alpha=16):\n",
        "        super().__init__()\n",
        "        self.linear_layer = linear_layer\n",
        "        self.rank = rank\n",
        "        self.alpha = alpha\n",
        "\n",
        "        self.register_buffer('pretrained_weight', linear_layer.weight.detach())\n",
        "        self.m = torch.nn.Parameter(self.pretrained_weight.norm(p=2, dim=0, keepdim=True))\n",
        "        self.lora_A = torch.nn.Parameter(torch.zeros(linear_layer.in_features, rank))\n",
        "        self.lora_B = torch.nn.Parameter(torch.zeros(rank, linear_layer.out_features))\n",
        "        self.scaling = self.alpha / self.rank\n",
        "\n",
        "        torch.nn.init.kaiming_uniform_(self.lora_A, a=math.sqrt(5))\n",
        "        torch.nn.init.zeros_(self.lora_B)\n",
        "\n",
        "    def forward(self, x):\n",
        "        w_d = F.normalize(self.pretrained_weight, p=2, dim=0)\n",
        "        lora_update = (self.lora_A @ self.lora_B) * self.scaling\n",
        "        combined_weight = self.m * w_d + lora_update\n",
        "        return F.linear(x, combined_weight, self.linear_layer.bias)\n"
      ],
      "metadata": {
        "id": "jppQ3KsAm_96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def apply_dora_to_model(model, rank, alpha, target_modules):\n",
        "    for name, module in model.named_modules():\n",
        "        if any(target_module in name for target_module in target_modules):\n",
        "            if isinstance(module, torch.nn.Linear):\n",
        "                parent_name = '.'.join(name.split('.')[:-1])\n",
        "                child_name = name.split('.')[-1]\n",
        "                parent_module = model.get_submodule(parent_name)\n",
        "                setattr(parent_module, child_name, DoRALayer(module, rank, alpha))"
      ],
      "metadata": {
        "id": "FE2GZtyeeA_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = 77  # For Banking77 dataset\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_labels\n",
        ")\n"
      ],
      "metadata": {
        "id": "pBpU6ngQeEtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- TUNED PARAMETER 1: Increased Rank and Alpha ---\n",
        "dora_rank = 16  # Increased from 8 to 16 for more capacity\n",
        "dora_alpha = 32 # Increased from 16 to 32 to maintain scaling (2*rank)\n",
        "\n",
        "apply_dora_to_model(model, dora_rank, dora_alpha, target_modules=[\"query\", \"value\"])\n",
        "model.to(device)\n",
        "print(f\" DoRA applied to the model with rank={dora_rank} and alpha={dora_alpha}.\")"
      ],
      "metadata": {
        "id": "Ca8TjUYMeHro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./dora_banking77_tuned_results',\n",
        "\n",
        "    # --- TUNED PARAMETER 2: Increased Epochs ---\n",
        "    num_train_epochs=6, # Increased from 3 to 5 for more training\n",
        "\n",
        "    # Batch size can be adjusted based on your new device's GPU memory\n",
        "    per_device_train_batch_size=16, # Kept at 16, a good default. Try 32 if you have more memory.\n",
        "    per_device_eval_batch_size=16,\n",
        "\n",
        "    # --- TUNED PARAMETER 3: Adjusted Learning Rate ---\n",
        "    learning_rate=3e-4, # Slightly lowered for potentially more stable convergence\n",
        "\n",
        "    weight_decay=0.01,\n",
        "\n",
        "    # --- TUNED PARAMETER 4: Added Warmup ---\n",
        "    warmup_ratio=0.1, # Added for training stability\n",
        "\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    logging_steps=50,\n",
        "    report_to=\"wandb\",\n",
        "\n",
        "    # New run name for clarity\n",
        "    run_name=\"dora-banking77-tuned-v1\",\n",
        ")"
      ],
      "metadata": {
        "id": "76qnCGEceJoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate -q\n"
      ],
      "metadata": {
        "id": "QgatG6mHqDMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = logits.argmax(axis=-1)\n",
        "    acc = accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
        "    return {\n",
        "        \"accuracy\": acc[\"accuracy\"],\n",
        "        \"f1\": f1[\"f1\"]\n",
        "    }\n"
      ],
      "metadata": {
        "id": "c1vJT1c-p18X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n"
      ],
      "metadata": {
        "id": "E-XnewPmeONA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting DoRA model training...\")\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "mnj3HmqAePko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating the final model...\")\n",
        "eval_metrics = trainer.evaluate()\n",
        "print(\"Evaluation Metrics:\", eval_metrics)"
      ],
      "metadata": {
        "id": "Ox3mmMnAeTdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.log(eval_metrics)\n"
      ],
      "metadata": {
        "id": "0YktnMMweU1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model_path = \"/content/drive/MyDrive/banking77_models/dora_final_model\"\n",
        "trainer.save_model(final_model_path)\n",
        "tokenizer.save_pretrained(final_model_path)\n",
        "print(f\"Final DoRA model saved to {final_model_path}\")"
      ],
      "metadata": {
        "id": "1nHkhUkGeWm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "id": "wNckdhBqeXhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(trainer.state.log_history)\n",
        "\n",
        "# Separate training and eval logs\n",
        "train_df = df[df[\"loss\"].notna()]\n",
        "eval_df = df[df[\"eval_loss\"].notna()]\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(3, 1, figsize=(10, 12), sharex=True)\n",
        "\n",
        "# --- Loss ---\n",
        "axes[0].plot(train_df[\"step\"], train_df[\"loss\"], label=\"Training Loss\", color=\"blue\", alpha=0.7)\n",
        "axes[0].plot(eval_df[\"step\"], eval_df[\"eval_loss\"], label=\"Eval Loss\", color=\"orange\", marker=\"o\")\n",
        "axes[0].set_ylabel(\"Loss\")\n",
        "axes[0].set_title(\"Training & Evaluation Loss\")\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, linestyle=\"--\", alpha=0.5)\n",
        "\n",
        "# --- Accuracy ---\n",
        "if \"eval_accuracy\" in eval_df:\n",
        "    axes[1].plot(eval_df[\"step\"], eval_df[\"eval_accuracy\"], label=\"Eval Accuracy\", color=\"green\", marker=\"o\")\n",
        "    max_acc_idx = eval_df[\"eval_accuracy\"].idxmax()\n",
        "    axes[1].scatter(eval_df.loc[max_acc_idx, \"step\"], eval_df.loc[max_acc_idx, \"eval_accuracy\"], color=\"red\", zorder=5)\n",
        "    axes[1].annotate(f\"Best: {eval_df.loc[max_acc_idx, 'eval_accuracy']:.4f}\",\n",
        "                     (eval_df.loc[max_acc_idx, \"step\"], eval_df.loc[max_acc_idx, \"eval_accuracy\"]),\n",
        "                     textcoords=\"offset points\", xytext=(10,5))\n",
        "    axes[1].set_ylabel(\"Accuracy\")\n",
        "    axes[1].set_title(\"Evaluation Accuracy Over Time\")\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, linestyle=\"--\", alpha=0.5)\n",
        "\n",
        "# --- F1-score ---\n",
        "if \"eval_f1\" in eval_df:\n",
        "    axes[2].plot(eval_df[\"step\"], eval_df[\"eval_f1\"], label=\"Eval F1-score\", color=\"purple\", marker=\"o\")\n",
        "    max_f1_idx = eval_df[\"eval_f1\"].idxmax()\n",
        "    axes[2].scatter(eval_df.loc[max_f1_idx, \"step\"], eval_df.loc[max_f1_idx, \"eval_f1\"], color=\"red\", zorder=5)\n",
        "    axes[2].annotate(f\"Best: {eval_df.loc[max_f1_idx, 'eval_f1']:.4f}\",\n",
        "                     (eval_df.loc[max_f1_idx, \"step\"], eval_df.loc[max_f1_idx, \"eval_f1\"]),\n",
        "                     textcoords=\"offset points\", xytext=(10,5))\n",
        "    axes[2].set_xlabel(\"Steps\")\n",
        "    axes[2].set_ylabel(\"F1-score\")\n",
        "    axes[2].set_title(\"Evaluation F1-score Over Time\")\n",
        "    axes[2].legend()\n",
        "    axes[2].grid(True, linestyle=\"--\", alpha=0.5)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qoZAYezuuWk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vw_qVXjkumOw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}