{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers accelerate peft datasets wandb bitsandbytes -q\n",
        "\n",
        "import os, torch, torch.nn as nn\n",
        "import pandas as pd, numpy as np\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import wandb\n"
      ],
      "metadata": {
        "id": "VGem0InJqIUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List"
      ],
      "metadata": {
        "id": "JCrrh-3dsoR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()\n",
        "os.environ[\"WANDB_PROJECT\"] = \"Banking77_MoE\"\n",
        "os.environ[\"WANDB_LOG_MODEL\"] = \"end\""
      ],
      "metadata": {
        "id": "7FM0YaznqIQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_CSV = \"/content/drive/MyDrive/Banking77_Project/data/train.csv\"\n",
        "TEST_CSV  = \"/content/drive/MyDrive/Banking77_Project/data/test.csv\"\n",
        "\n",
        "train_df = pd.read_csv(TRAIN_CSV)\n",
        "test_df  = pd.read_csv(TEST_CSV)\n",
        "\n",
        "# Auto-detect text column\n",
        "possible_text_cols = [\"text\", \"utterance\", \"sentence\", \"query\", \"question\", \"content\"]\n",
        "text_col = None\n",
        "for c in possible_text_cols:\n",
        "    if c in train_df.columns:\n",
        "        text_col = c\n",
        "        break\n",
        "if text_col is None:\n",
        "    # fallback: take first string column\n",
        "    for c in train_df.columns:\n",
        "        if train_df[c].dtype == object:\n",
        "            text_col = c\n",
        "            break\n",
        "if text_col is None:\n",
        "    raise ValueError(f\"No text-like column found. Columns: {train_df.columns}\")\n",
        "\n",
        "# Normalize to 'text'\n",
        "train_df = train_df.rename(columns={text_col: \"text\"})\n",
        "test_df  = test_df.rename(columns={text_col: \"text\"})\n",
        "\n",
        "# Auto-detect label column\n",
        "if \"label\" in train_df.columns:\n",
        "    label_col = \"label\"\n",
        "elif \"category\" in train_df.columns:\n",
        "    label_col = \"category\"\n",
        "elif \"intent\" in train_df.columns:\n",
        "    label_col = \"intent\"\n",
        "elif \"target\" in train_df.columns:\n",
        "    label_col = \"target\"\n",
        "else:\n",
        "    # try numeric column that looks like label\n",
        "    numeric_cols = [c for c in train_df.columns if np.issubdtype(train_df[c].dtype, np.integer)]\n",
        "    if len(numeric_cols) > 0:\n",
        "        label_col = numeric_cols[0]\n",
        "    else:\n",
        "        raise ValueError(f\"No label-like column found. Columns: {train_df.columns}\")\n",
        "\n",
        "# Normalize to 'label'\n",
        "if label_col != \"label\":\n",
        "    train_df = train_df.rename(columns={label_col: \"label\"})\n",
        "    test_df  = test_df.rename(columns={label_col: \"label\"})\n",
        "\n",
        "# Map string labels to ints if needed\n",
        "if train_df[\"label\"].dtype == object or test_df[\"label\"].dtype == object:\n",
        "    all_labels = pd.concat([train_df[\"label\"], test_df[\"label\"]]).unique()\n",
        "    label2id = {lab: i for i, lab in enumerate(sorted(all_labels))}\n",
        "    train_df[\"label\"] = train_df[\"label\"].map(label2id).astype(int)\n",
        "    test_df[\"label\"]  = test_df[\"label\"].map(label2id).astype(int)\n",
        "else:\n",
        "    # numeric labels assumed OK\n",
        "    all_labels = pd.concat([train_df[\"label\"], test_df[\"label\"]]).unique()\n",
        "    label2id = {int(l): int(l) for l in sorted(all_labels)}\n",
        "\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "num_labels = len(label2id)\n",
        "print(f\"Detected text column: '{text_col}', label column mapped -> 'label', num_labels = {num_labels}\")\n"
      ],
      "metadata": {
        "id": "1sDa13t8qION"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = DatasetDict({\n",
        "    \"train\": Dataset.from_pandas(train_df.reset_index(drop=True)),\n",
        "    \"test\": Dataset.from_pandas(test_df.reset_index(drop=True))\n",
        "})\n"
      ],
      "metadata": {
        "id": "OyEIVJg4qILk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expert_model_names = [\n",
        "    \"bert-base-uncased\",\n",
        "    \"distilbert-base-uncased\",\n",
        "    \"gpt2\",\n",
        "    \"distilgpt2\"\n",
        "]"
      ],
      "metadata": {
        "id": "SgJSEWlhqII9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\", use_fast=True)\n",
        "if tokenizer.pad_token is None:\n",
        "    # ensure pad token exists (some tokenizers like GPT2 lack it)\n",
        "    tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
        "    print(\"Added pad token to tokenizer\")\n",
        "\n",
        "# Tokenize dataset\n",
        "def tokenize_fn(examples, max_length=64):\n",
        "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=max_length)\n",
        "\n",
        "tokenized = dataset.map(lambda x: tokenize_fn(x, max_length=64), batched=True)\n",
        "# rename label column to 'labels' expected by Trainer\n",
        "if \"label\" in tokenized[\"train\"].column_names:\n",
        "    tokenized = tokenized.rename_column(\"label\", \"labels\")\n",
        "\n",
        "# remove unnecessary columns that could break Trainer\n",
        "cols_to_keep = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
        "tokenized = tokenized.map(lambda ex: {k: ex[k] for k in cols_to_keep}, batched=True)\n"
      ],
      "metadata": {
        "id": "yhDLm308qT8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def auto_detect_target_modules(model: AutoModelForSequenceClassification, model_name_hint: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Inspect model.named_modules() and pick candidate substrings that exist.\n",
        "    Returns a list of substrings to use as target_modules for PEFT LoRA.\n",
        "    \"\"\"\n",
        "    all_module_names = [n for n, _ in model.named_modules()]\n",
        "    # candidate substrings per family (expandable)\n",
        "    families = {\n",
        "        \"bert\": [\"attention.self.query\", \"attention.self.key\", \"attention.self.value\", \"attention.output.dense\", \"dense\", \"query\", \"key\", \"value\"],\n",
        "        \"distilbert\": [\"attention.q_lin\", \"attention.k_lin\", \"attention.v_lin\", \"attention.out_lin\", \"q_lin\", \"k_lin\", \"v_lin\", \"out_lin\"],\n",
        "        \"gpt2\": [\"attn.c_attn\", \"attn.c_proj\", \"c_attn\", \"c_proj\"],\n",
        "        \"distilgpt2\": [\"attn.c_attn\", \"attn.c_proj\", \"c_attn\", \"c_proj\"]\n",
        "    }\n",
        "\n",
        "    # choose family by hint\n",
        "    family_key = None\n",
        "    for k in families.keys():\n",
        "        if k in model_name_hint:\n",
        "            family_key = k\n",
        "            break\n",
        "    if family_key is None:\n",
        "        # fallback: try all families\n",
        "        cand_subs = sum(families.values(), [])\n",
        "    else:\n",
        "        cand_subs = families[family_key]\n",
        "\n",
        "    # keep only those substrings which exist in module names\n",
        "    found = []\n",
        "    for sub in cand_subs:\n",
        "        if any(sub in mn for mn in all_module_names):\n",
        "            found.append(sub)\n",
        "\n",
        "    # final fallback: try a small safe set\n",
        "    if not found:\n",
        "        # try some broad substrings\n",
        "        for sub in [\"query\", \"key\", \"value\", \"dense\", \"c_attn\", \"c_proj\", \"q_lin\", \"k_lin\", \"v_lin\", \"out_lin\"]:\n",
        "            if any(sub in mn for mn in all_module_names):\n",
        "                found.append(sub)\n",
        "    return found\n"
      ],
      "metadata": {
        "id": "j9qjh2xGshYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_peft_model_auto(model_name: str, num_labels: int):\n",
        "    print(f\"\\n--> Loading base model for {model_name} ...\")\n",
        "    base = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
        "\n",
        "    if \"gpt2\" in model_name:\n",
        "        base.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "    targets = auto_detect_target_modules(base, model_name)\n",
        "    if not targets:\n",
        "        sample_mods = [n for n, _ in list(base.named_modules())[:80]]\n",
        "        raise ValueError(f\"No suitable LoRA target modules found for {model_name}. Sample modules:\\n{sample_mods[:40]}\")\n",
        "    print(f\"Detected target_modules for {model_name}: {targets}\")\n",
        "\n",
        "    peft_config = LoraConfig(\n",
        "        r=8,\n",
        "        lora_alpha=32,\n",
        "        lora_dropout=0.1,\n",
        "        bias=\"none\",\n",
        "        task_type=\"SEQ_CLS\",\n",
        "        target_modules=targets\n",
        "    )\n",
        "    peft_model = get_peft_model(base, peft_config)\n",
        "    print(f\"--> PEFT model ready for {model_name}\")\n",
        "    return peft_model\n"
      ],
      "metadata": {
        "id": "ivirgCpQsud7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experts = []\n",
        "for nm in expert_model_names:\n",
        "    try:\n",
        "        m = make_peft_model_auto(nm, num_labels=num_labels)\n",
        "        experts.append(m)\n",
        "    except Exception as e:\n",
        "        print(f\"Error building PEFT expert for {nm}: {e}\")\n",
        "        raise\n",
        "\n",
        "if len(experts) == 0:\n",
        "    raise RuntimeError(\"No experts were successfully created.\")\n",
        "\n",
        "print(f\"Created {len(experts)} experts.\")\n"
      ],
      "metadata": {
        "id": "Np0-MOy-svXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridMoE(nn.Module):\n",
        "    def __init__(self, experts: List[nn.Module], hidden_dim: int = 768, top_k: int = 2):\n",
        "        super().__init__()\n",
        "        self.experts = nn.ModuleList(experts)\n",
        "        self.num_experts = len(self.experts)\n",
        "        self.top_k = top_k\n",
        "        # router takes averaged hidden and outputs num_experts scores\n",
        "        self.router = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, self.num_experts)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
        "        device = input_ids.device if input_ids is not None else next(self.parameters()).device\n",
        "\n",
        "        # Each expert run: get logits and last hidden (CLS or first token)\n",
        "        expert_logits = []\n",
        "        hidden_states = []\n",
        "        for i, expert in enumerate(self.experts):\n",
        "            # Ensure expert is on the same device temporarily\n",
        "            expert.to(device)\n",
        "            outputs = expert(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
        "            # outputs.logits shape: (B, num_labels)\n",
        "            expert_logits.append(outputs.logits)\n",
        "            # outputs.hidden_states[-1] might be (B, seq_len, hidden_dim)\n",
        "            last_hidden = outputs.hidden_states[-1][:, 0, :].detach()  # take first token (CLS)\n",
        "            hidden_states.append(last_hidden)\n",
        "            # Move expert back to CPU if memory is constrained (optional)\n",
        "            # expert.to(\"cpu\")\n",
        "\n",
        "        # stack hidden states: (B, num_experts, hidden_dim) -> mean over experts -> (B, hidden_dim)\n",
        "        hidden_states = torch.stack(hidden_states, dim=1).mean(dim=1)\n",
        "        router_scores = self.router(hidden_states)  # (B, num_experts)\n",
        "\n",
        "        # top-k gating\n",
        "        k = min(self.top_k, self.num_experts)\n",
        "        topk_vals, topk_idx = torch.topk(router_scores, k, dim=-1)  # (B, k)\n",
        "        topk_weights = torch.softmax(topk_vals, dim=-1)  # (B, k)\n",
        "\n",
        "        # Weighted combination of expert logits\n",
        "        batch_logits = torch.zeros_like(expert_logits[0])\n",
        "        B = batch_logits.size(0)\n",
        "        for i in range(k):\n",
        "            idx = topk_idx[:, i]  # (B,)\n",
        "            w   = topk_weights[:, i].unsqueeze(-1)  # (B,1)\n",
        "            # sum: for each batch element pick expert idx[b] and weight w[b]\n",
        "            for b in range(B):\n",
        "                batch_logits[b] += w[b] * expert_logits[idx[b]][b]\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = nn.CrossEntropyLoss()(batch_logits, labels)\n",
        "        return {\"loss\": loss, \"logits\": batch_logits}\n",
        "\n",
        "# 10) Instantiate MoE\n",
        "moe_model = HybridMoE(experts=experts, hidden_dim=768, top_k=2)\n",
        "print(\"HybridMoE created with\", len(experts), \"experts.\")\n"
      ],
      "metadata": {
        "id": "Wi1XQvUxsyi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(labels, preds),\n",
        "        \"f1\": f1_score(labels, preds, average=\"weighted\")\n",
        "    }"
      ],
      "metadata": {
        "id": "FhayPkUBs45y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/Banking77_Project/outputs_moe4_peft_auto\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-4,\n",
        "    per_device_train_batch_size=4,   # conservative for T4 (reduce if OOM)\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs_moe4_peft\",\n",
        "    report_to=\"wandb\",    # set to [] or remove if not using W&B\n",
        "    run_name=\"HybridMoE_4Experts_PEFT_auto\",\n",
        "    fp16=True\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=moe_model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized[\"train\"],\n",
        "    eval_dataset=tokenized[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "LeS0foi0s86D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "IczU82BJs9FY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N1gpqXJbtAnz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}