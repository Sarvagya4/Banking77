{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sarvagya4/Banking77/blob/main/Finetune_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vb-loaV_t5Gd"
      },
      "outputs": [],
      "source": [
        "!pip install transformers[torch] datasets pandas scikit-learn wandb evaluate -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import wandb\n",
        "from datetime import timedelta\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from getpass import getpass\n",
        "\n",
        "\n",
        "import torch\n",
        "import wandb\n",
        "import evaluate\n",
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")"
      ],
      "metadata": {
        "id": "ZLWShOTtt_OA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    BASE_DIR = \"/content/drive/MyDrive/Banking77_Project\"\n",
        "except ImportError:\n",
        "    BASE_DIR = \"./Banking77_Project\"\n",
        "    print(\"Not in Google Colab. Using local directory for project files.\")\n",
        "\n",
        "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
        "MODEL_DIR = os.path.join(BASE_DIR, \"models\", \"bert-full-finetune\")\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Project directory: {BASE_DIR}\")\n",
        "print(f\"Data directory: {DATA_DIR}\")\n",
        "print(f\"Model will be saved in: {MODEL_DIR}\")"
      ],
      "metadata": {
        "id": "OEVmbp2zwiBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/drive/MyDrive -type f -name \"train.csv\"\n"
      ],
      "metadata": {
        "id": "FJTtELHMg8NG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "DATA_DIR = \"/content/drive/MyDrive/Banking77_Project/data\"\n",
        "print(os.listdir(DATA_DIR))\n"
      ],
      "metadata": {
        "id": "Si0g_F_KglUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    wandb_key = getpass(\"Enter your Weights & Biases API key: \")\n",
        "    wandb.login(key=wandb_key)\n",
        "except Exception as e:\n",
        "    print(f\"Could not log in to W&B. Please check your API key. Error: {e}\")"
      ],
      "metadata": {
        "id": "WJKQvgx5wvnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
        "val_df = pd.read_csv(os.path.join(DATA_DIR, 'validation.csv'))\n",
        "test_df = pd.read_csv(os.path.join(DATA_DIR, 'test.csv'))"
      ],
      "metadata": {
        "id": "5fwRZxVpw2VH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df)"
      ],
      "metadata": {
        "id": "SPFObQIzOhjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = {i: label for i, label in enumerate(train_df['intent'].astype('category').cat.categories)}\n",
        "label2id = {label: i for i, label in id2label.items()}\n",
        "NUM_LABELS = len(id2label)"
      ],
      "metadata": {
        "id": "ocZ6wdtIxN2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df)"
      ],
      "metadata": {
        "id": "x5hwewBHOoQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.rename(columns={'intent': 'label'}, inplace=True)\n",
        "val_df.rename(columns={'intent': 'label'}, inplace=True)\n",
        "test_df.rename(columns={'intent': 'label'}, inplace=True)"
      ],
      "metadata": {
        "id": "17IAZcCWxQO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df)"
      ],
      "metadata": {
        "id": "SJsAW16cOsNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "dataset_dict = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'validation': val_dataset,\n",
        "    'test': test_dataset\n",
        "})\n",
        "\n",
        "print(\"Datasets loaded successfully:\")\n",
        "print(dataset_dict)"
      ],
      "metadata": {
        "id": "WoITYHR9xTFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(\n",
        "    project=\"Banking77-Intent-Classification\",\n",
        "    job_type=\"train\",\n",
        "    name=\"day2-bert-full-finetune\",\n",
        "    notes=\"Fine-tuning a standard BERT model on the Banking77 dataset.\"\n",
        ")"
      ],
      "metadata": {
        "id": "suj50hw5xWNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"bert-base-uncased\""
      ],
      "metadata": {
        "id": "YGum6iXrxYmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "s0_XH0-UxcVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=NUM_LABELS,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")"
      ],
      "metadata": {
        "id": "N201dRt9xdv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    # Use the 'text_cleaned' column created in Day 1.\n",
        "    return tokenizer(examples[\"text_cleaned\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_datasets = dataset_dict.map(tokenize_function, batched=True)\n",
        "print(\"\\nDatasets tokenized:\")\n",
        "print(tokenized_datasets)"
      ],
      "metadata": {
        "id": "kpjWq8cvxgdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_dict)"
      ],
      "metadata": {
        "id": "Il8u0nXZO8ZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy[\"accuracy\"],\n",
        "        \"f1\": f1[\"f1\"],\n",
        "    }"
      ],
      "metadata": {
        "id": "8Yet37BJxlAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=MODEL_DIR,\n",
        "    num_train_epochs=6,\n",
        "    learning_rate=1e-5,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    warmup_ratio=0.1,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    logging_dir=f\"{MODEL_DIR}/logs\",\n",
        "    logging_steps=100,\n",
        "    fp16=True,\n",
        "    report_to=\"wandb\"\n",
        ")"
      ],
      "metadata": {
        "id": "huz5M1BHxpLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "yZkDF4BSzfC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting model training...\")\n",
        "trainer.train()\n",
        "print(\"Training finished.\")"
      ],
      "metadata": {
        "id": "Qh08EeE80SQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example training history structure\n",
        "# Replace these with the lists you populate during training\n",
        "train_losses = []  # append training loss each epoch\n",
        "val_losses = []    # append validation loss each epoch\n",
        "train_acc = []     # append training accuracy each epoch\n",
        "val_acc = []       # append validation accuracy each epoch\n",
        "\n",
        "# Example: after your training loop is done, visualize it\n",
        "def plot_training_history(train_losses, val_losses, train_acc=None, val_acc=None):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Loss plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_losses, 'b-', label='Training Loss')\n",
        "    plt.plot(epochs, val_losses, 'r-', label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss over Epochs')\n",
        "    plt.legend()\n",
        "\n",
        "    # Accuracy plot\n",
        "    if train_acc and val_acc:\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(epochs, train_acc, 'b-', label='Training Accuracy')\n",
        "        plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title('Accuracy over Epochs')\n",
        "        plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example call after training\n",
        "plot_training_history(train_losses, val_losses, train_acc, val_acc)\n"
      ],
      "metadata": {
        "id": "ryTMqVi5CD-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "X_train = torch.randn(500, 100)\n",
        "y_train = torch.randint(0, 10, (500,))\n",
        "X_val = torch.randn(100, 100)\n",
        "y_val = torch.randint(0, 10, (100,))\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=32)\n",
        "\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(100, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 10)\n",
        ")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "train_losses, val_losses = [], []\n",
        "train_acc, val_acc = [], []\n",
        "\n",
        "\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        correct += (predicted == y_batch).sum().item()\n",
        "        total += y_batch.size(0)\n",
        "\n",
        "    train_losses.append(total_loss / len(train_loader))\n",
        "    train_acc.append(correct / total)\n",
        "\n",
        "    model.eval()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "            total += y_batch.size(0)\n",
        "\n",
        "    val_losses.append(total_loss / len(val_loader))\n",
        "    val_acc.append(correct / total)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - \"\n",
        "          f\"Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_acc[-1]:.4f}, \"\n",
        "          f\"Val Loss: {val_losses[-1]:.4f}, Val Acc: {val_acc[-1]:.4f}\")\n",
        "\n",
        "\n",
        "epochs_range = range(1, epochs + 1)\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, train_losses, label='Training Loss')\n",
        "plt.plot(epochs_range, val_losses, label='Validation Loss')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss Over Epochs\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, train_acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy Over Epochs\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "XcHCcAJyvS6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GkTT5o2Ivc1z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}