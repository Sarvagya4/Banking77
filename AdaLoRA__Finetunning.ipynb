{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caSYXbOo05ka"
      },
      "outputs": [],
      "source": [
        "!pip install transformers huggingface_hub -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHKYnCFyw7Vh"
      },
      "outputs": [],
      "source": [
        "!pip install datasets wandb accelerate peft -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nloSQ_8GxAoO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import torch\n",
        "import warnings\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    DataCollatorWithPadding,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        ")\n",
        "\n",
        "\n",
        "from transformers.integrations import WandbCallback\n",
        "from datasets import load_dataset, Dataset\n",
        "import wandb\n",
        "from peft import get_peft_model, AdaLoraConfig, TaskType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Uy-ftKHzldS"
      },
      "outputs": [],
      "source": [
        "\n",
        "from huggingface_hub import login\n",
        "from transformers import AutoConfig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZdQN4691pzI"
      },
      "outputs": [],
      "source": [
        "HF_TOKEN = \"\"\n",
        "os.environ[\"HUGGING_FACE_HUB_TOKEN\"] = HF_TOKEN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3kpYRFM1qaT"
      },
      "outputs": [],
      "source": [
        "\n",
        "login(token=HF_TOKEN, add_to_git_credential=False)\n",
        "\n",
        "config = AutoConfig.from_pretrained(\"bert-base-uncased\", use_auth_token=HF_TOKEN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsGFIKJKxNeN"
      },
      "outputs": [],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fvtxHv1xR1M"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0iJOB1DxTgb"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnsBZyNixWWj"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    data_path_prefix = \"/content/drive/MyDrive/Banking77_Project/data/\"\n",
        "    data_files = {\n",
        "        \"train\": os.path.join(data_path_prefix, \"train.csv\"),\n",
        "        \"validation\": os.path.join(data_path_prefix, \"validation.csv\"),\n",
        "        \"test\": os.path.join(data_path_prefix, \"test.csv\")\n",
        "    }\n",
        "\n",
        "    # Load into a DatasetDict\n",
        "    dataset = load_dataset(\"csv\", data_files=data_files)\n",
        "\n",
        "    print(\" Successfully loaded datasets from Google Drive.\")\n",
        "    print(dataset)\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\" Error: A required data file was not found.\")\n",
        "    print(f\"Please ensure 'train.csv', 'validation.csv', and 'test.csv' exist in '{data_path_prefix}'\")\n",
        "    sys.exit(\"\\nScript terminated due to missing files.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXYWXRtzUcQp"
      },
      "outputs": [],
      "source": [
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWU6rPNwxaP9"
      },
      "outputs": [],
      "source": [
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Rename the 'intent' column to 'label' for the Trainer\n",
        "dataset = dataset.rename_column(\"label\", \"labels\")\n",
        "print(\" Renamed 'intent' column to 'label'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phXQ-sh6a16k"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    f1 = f1_score(labels, predictions, average='weighted')  # Use 'micro' or 'macro' as needed\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNUiVKZdU06d"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['text'], truncation=True, max_length=128, padding='max_length')\n",
        "\n",
        "# Tokenize\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# No need to rename (labels already exists)\n",
        "tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "\n",
        "print(\"Data preprocessing and formatting complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BH-yMxSFxfv7"
      },
      "outputs": [],
      "source": [
        "from peft import AdaLoraConfig, TaskType\n",
        "\n",
        "# Calculate total steps\n",
        "num_train_samples = len(tokenized_dataset[\"train\"])\n",
        "batch_size = 16  # per_device_train_batch_size\n",
        "epochs = 9\n",
        "\n",
        "steps_per_epoch = num_train_samples // batch_size\n",
        "total_steps = steps_per_epoch * epochs\n",
        "\n",
        "adalora_config = AdaLoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    r=12,              # Initial rank\n",
        "    target_r=8,        # Target average rank\n",
        "    init_r=12,         # The rank of the SVD matrix to be initialized\n",
        "    tinit=200,         # Steps before rank allocation starts\n",
        "    tfinal=1000,       # Steps when rank allocation ends\n",
        "    deltaT=100,        # Frequency of rank allocation budget updates\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    inference_mode=False,\n",
        "    total_step=total_steps,\n",
        "    target_modules=[\"query\", \"value\"], # Apply AdaLoRA to query and value layers\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUtHGdqJxjhD"
      },
      "outputs": [],
      "source": [
        "num_labels = 77\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5gM1mwOxlKD"
      },
      "outputs": [],
      "source": [
        "model = get_peft_model(model, adalora_config)\n",
        "model.print_trainable_parameters()\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-w56Mfe3q6e"
      },
      "outputs": [],
      "source": [
        "wandb.init(\n",
        "    project=\"adalora-banking77\",  # change to your project name\n",
        "    name=\"adalora-banking77-run1\",  # custom run name\n",
        "    config={\n",
        "        \"epochs\": 9,\n",
        "        \"batch_size\": 16,\n",
        "        \"learning_rate\": 1e-3,\n",
        "        \"model_name\": \"bert-base-uncased\",\n",
        "        \"peft_method\": \"AdaLoRA\"\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"WandB initialized. Tracking metrics...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iN816l1zxn3z"
      },
      "outputs": [],
      "source": [
        "class RankLoggerCallback(WandbCallback):\n",
        "    def on_log(self, args, state, control, **kwargs):\n",
        "        super().on_log(args, state, control, **kwargs)\n",
        "        # Log the current rank allocation for each layer\n",
        "        rank_pattern = model.peft_config['default'].rank_pattern\n",
        "        if rank_pattern:\n",
        "            # Create a dictionary to log: {layer_name: rank}\n",
        "            ranks_to_log = {key: val for key, val in rank_pattern.items()}\n",
        "            wandb.log({\"rank_allocation\": ranks_to_log})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztdpxOLTxq9S"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./adalora_banking77_results',\n",
        "    num_train_epochs=9, # More epochs can be useful for AdaLoRA to stabilize ranks\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=1e-3, # AdaLoRA often works well with a higher learning rate\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    logging_steps=100, # Log every 100 steps to see rank changes\n",
        "    report_to=\"wandb\",\n",
        "    run_name=\"adalora-banking77-dynamic-rank\",\n",
        "    metric_for_best_model=\"accuracy\",  # Track accuracy for best model selection\n",
        "    greater_is_better=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNKuDynzxzuy"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "    callbacks=[RankLoggerCallback()],\n",
        "    compute_metrics=compute_metrics,# Add our custom callback here\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDMwTIKjx2BD"
      },
      "outputs": [],
      "source": [
        "print(\" Starting AdaLoRA model training...\")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JyWEJT1g3bQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}